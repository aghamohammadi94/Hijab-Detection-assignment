{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load used libraries\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2 # for reading images\n",
    "import mediapipe as mp # for face detection\n",
    "\n",
    "\n",
    "# the directory of images downloaded from the Internet for model training\n",
    "downloaded_dataset = './downloads'\n",
    "\n",
    "# the folder of recognized faces from downloaded images for data collection\n",
    "base_dir = './images'\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# classification of images hijab\n",
    "hijab_dir = os.path.join(base_dir, 'hijab')\n",
    "os.makedirs(hijab_dir, exist_ok=True)\n",
    "\n",
    "# classification of images without hijab\n",
    "without_hijab_dir = os.path.join(base_dir, 'without_hijab')\n",
    "os.makedirs(without_hijab_dir, exist_ok=True)\n",
    "\n",
    "# create a Face Detection object\n",
    "fd = mp.solutions.face_detection.FaceDetection(min_detection_confidence=0.5)\n",
    "\n",
    "\n",
    "hijab = []\n",
    "without_hijab = []\n",
    "\n",
    "for root, dirs, files in os.walk(downloaded_dataset):\n",
    "    for file in files:\n",
    "        \n",
    "        if file[0:3] == 'yes':\n",
    "            hijab.append(file)\n",
    "            \n",
    "        if file[0:3] == 'no ':\n",
    "            without_hijab.append(file)\n",
    "\n",
    "\n",
    "# separating the face from the images\n",
    "for name in hijab:\n",
    "    path = os.path.join(downloaded_dataset, name)\n",
    "    picture = cv2.imread(path)\n",
    "    \n",
    "    # convert picture to RGB format\n",
    "    picture = cv2.cvtColor(picture, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # process picture with Face Detection\n",
    "    result = fd.process(picture)\n",
    "    \n",
    "    # get detections attribute from result object\n",
    "    detections = result.detections\n",
    "    \n",
    "    if detections:\n",
    "            \n",
    "        # loop over detected faces\n",
    "        for i, detection in enumerate(detections):\n",
    "            \n",
    "            # get bounding box coordinates of face\n",
    "            ih, iw, ic = picture.shape\n",
    "            \n",
    "            # create a border to fit the hijab cover or hair inside the cropped image\n",
    "            margin = 15\n",
    "            \n",
    "            xmin = int(detection.location_data.relative_bounding_box.xmin * iw - margin)\n",
    "            \n",
    "            ymin = int(detection.location_data.relative_bounding_box.ymin * ih - margin)\n",
    "            \n",
    "            width = int((detection.location_data.relative_bounding_box.xmin + detection.location_data.relative_bounding_box.width) * iw + margin)\n",
    "            \n",
    "            height = int((detection.location_data.relative_bounding_box.ymin + detection.location_data.relative_bounding_box.height) * ih + margin)\n",
    "            \n",
    "            # diagnosed box around the face\n",
    "            box = (xmin,ymin,width,height)\n",
    "            \n",
    "            img = Image.open(path)\n",
    "            img = img.convert('RGB')\n",
    "               \n",
    "            # cut the face area and save it\n",
    "            img = img.crop(box)\n",
    "            img.save(os.path.join(hijab_dir,f'{name[:-4]}{i}.jpg'))\n",
    "            \n",
    "            \n",
    "# separating the face from the images\n",
    "for name in without_hijab:\n",
    "    path = os.path.join(downloaded_dataset, name)\n",
    "    picture = cv2.imread(path)\n",
    "    \n",
    "    # convert picture to RGB format\n",
    "    picture = cv2.cvtColor(picture, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # process picture with Face Detection\n",
    "    result = fd.process(picture)\n",
    "    \n",
    "    # get detections attribute from result object\n",
    "    detections = result.detections\n",
    "    \n",
    "    if detections:\n",
    "            \n",
    "        # loop over detected faces\n",
    "        for i, detection in enumerate(detections):\n",
    "            \n",
    "            # get bounding box coordinates of face\n",
    "            ih, iw, ic = picture.shape\n",
    "            \n",
    "            # create a border to fit the hijab cover or hair inside the cropped image\n",
    "            margin = 30\n",
    "            \n",
    "            xmin = int(detection.location_data.relative_bounding_box.xmin * iw - margin)\n",
    "            \n",
    "            ymin = int(detection.location_data.relative_bounding_box.ymin * ih - margin)\n",
    "            \n",
    "            width = int((detection.location_data.relative_bounding_box.xmin + detection.location_data.relative_bounding_box.width) * iw + margin)\n",
    "            \n",
    "            height = int((detection.location_data.relative_bounding_box.ymin + detection.location_data.relative_bounding_box.height) * ih + margin)\n",
    "            \n",
    "            # diagnosed box around the face\n",
    "            box = (xmin,ymin,width,height)\n",
    "            \n",
    "            img = Image.open(path)\n",
    "            img = img.convert('RGB')\n",
    "               \n",
    "            # cut the face area and save it\n",
    "            img = img.crop(box)\n",
    "            img.save(os.path.join(without_hijab_dir,f'{name[:-4]}{i}.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
